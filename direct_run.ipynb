{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "921112dc",
   "metadata": {},
   "source": [
    "# Fake News Detection model in AWS SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf23387",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ffbb280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.46.1-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting flax\n",
      "  Downloading flax-0.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting tf-keras\n",
      "  Downloading tf_keras-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (3.16.1)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
      "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
      "  Downloading tokenizers-0.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (4.66.5)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (4.25.5)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.67.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Downloading keras-3.6.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (3.11.0)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Collecting jax>=0.4.27 (from flax)\n",
      "  Downloading jax-0.4.35-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: msgpack in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from flax) (1.1.0)\n",
      "Collecting optax (from flax)\n",
      "  Downloading optax-0.2.3-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting orbax-checkpoint (from flax)\n",
      "  Downloading orbax_checkpoint-0.8.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting tensorstore (from flax)\n",
      "  Downloading tensorstore-0.1.67-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: rich>=11.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from flax) (13.8.1)\n",
      "Collecting accelerate>=0.26.0 (from transformers[torch])\n",
      "  Downloading accelerate-1.0.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting torch (from transformers[torch])\n",
      "  Downloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from accelerate>=0.26.0->transformers[torch]) (6.0.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Collecting jaxlib<=0.4.35,>=0.4.34 (from jax>=0.4.27->flax)\n",
      "  Downloading jaxlib-0.4.35-cp310-cp310-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
      "Requirement already satisfied: scipy>=1.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jax>=0.4.27->flax) (1.14.1)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Downloading optree-0.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (47 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from rich>=11.1->flax) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from rich>=11.1->flax) (2.18.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch->transformers[torch]) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch->transformers[torch]) (3.1.4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->transformers[torch])\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->transformers[torch])\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->transformers[torch])\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->transformers[torch])\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->transformers[torch])\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->transformers[torch])\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->transformers[torch])\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->transformers[torch])\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->transformers[torch])\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch->transformers[torch])\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch->transformers[torch])\n",
      "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->transformers[torch])\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.1.0 (from torch->transformers[torch])\n",
      "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting sympy==1.13.1 (from torch->transformers[torch])\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sympy==1.13.1->torch->transformers[torch]) (1.3.0)\n",
      "Collecting chex>=0.1.86 (from optax->flax)\n",
      "  Downloading chex-0.1.87-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting etils[epy] (from optax->flax)\n",
      "  Downloading etils-1.10.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: nest_asyncio in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from orbax-checkpoint->flax) (1.6.0)\n",
      "Collecting humanize (from orbax-checkpoint->flax)\n",
      "  Downloading humanize-4.11.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: toolz>=0.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from chex>=0.1.86->optax->flax) (0.12.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: importlib_resources in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from etils[epath,epy]->orbax-checkpoint->flax) (6.4.5)\n",
      "Requirement already satisfied: zipp in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from etils[epath,epy]->orbax-checkpoint->flax) (3.20.2)\n",
      "Downloading transformers-4.46.1-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m153.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.3/615.3 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading flax-0.10.0-py3-none-any.whl (420 kB)\n",
      "Downloading tf_keras-2.18.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m127.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading accelerate-1.0.1-py3-none-any.whl (330 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading grpcio-1.67.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m181.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "Downloading jax-0.4.35-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m111.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.6.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m110.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m191.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m138.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m130.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m159.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading tokenizers-0.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m132.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.4/906.4 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m141.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m147.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m134.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m133.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m135.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m114.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m182.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m136.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading optax-0.2.3-py3-none-any.whl (289 kB)\n",
      "Downloading orbax_checkpoint-0.8.0-py3-none-any.whl (286 kB)\n",
      "Downloading tensorstore-0.1.67-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m153.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading chex-0.1.87-py3-none-any.whl (99 kB)\n",
      "Downloading jaxlib-0.4.35-cp310-cp310-manylinux2014_x86_64.whl (87.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.3/87.3 MB\u001b[0m \u001b[31m149.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading humanize-4.11.0-py3-none-any.whl (128 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (358 kB)\n",
      "Downloading etils-1.10.0-py3-none-any.whl (164 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, triton, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, sympy, safetensors, optree, opt-einsum, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ml-dtypes, humanize, grpcio, gast, etils, astunparse, absl-py, tensorstore, tensorboard, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jaxlib, huggingface-hub, tokenizers, nvidia-cusolver-cu12, keras, jax, transformers, torch, tensorflow, orbax-checkpoint, chex, tf-keras, optax, accelerate, flax\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.2\n",
      "    Uninstalling sympy-1.13.2:\n",
      "      Successfully uninstalled sympy-1.13.2\n",
      "Successfully installed absl-py-2.1.0 accelerate-1.0.1 astunparse-1.6.3 chex-0.1.87 etils-1.10.0 flatbuffers-24.3.25 flax-0.10.0 gast-0.6.0 grpcio-1.67.1 huggingface-hub-0.26.2 humanize-4.11.0 jax-0.4.35 jaxlib-0.4.35 keras-3.6.0 libclang-18.1.1 ml-dtypes-0.4.1 namex-0.0.8 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 opt-einsum-3.4.0 optax-0.2.3 optree-0.13.0 orbax-checkpoint-0.8.0 safetensors-0.4.5 sympy-1.13.1 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-io-gcs-filesystem-0.37.1 tensorstore-0.1.67 termcolor-2.5.0 tf-keras-2.18.0 tokenizers-0.20.1 torch-2.5.1 transformers-4.46.1 triton-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers tensorflow flax tf-keras transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ca0ab13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.5.1\n",
      "Uninstalling torch-2.5.1:\n",
      "  Successfully uninstalled torch-2.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8461e119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cpu\n",
      "Collecting torch==1.13.0\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torch-1.13.0%2Bcpu-cp310-cp310-linux_x86_64.whl (198.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.5/198.5 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchvision==0.14.0\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.14.0%2Bcpu-cp310-cp310-linux_x86_64.whl (16.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchaudio==0.13.0\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchaudio-0.13.0%2Bcpu-cp310-cp310-linux_x86_64.whl (4.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==1.13.0) (4.12.2)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torchvision==0.14.0) (1.26.4)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torchvision==0.14.0) (2.32.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torchvision==0.14.0) (10.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->torchvision==0.14.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->torchvision==0.14.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->torchvision==0.14.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->torchvision==0.14.0) (2024.8.30)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "Successfully installed torch-1.13.0+cpu torchaudio-0.13.0+cpu torchvision-0.14.0+cpu\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.13.0 torchvision==0.14.0 torchaudio==0.13.0 --extra-index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "650af87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: tensorflow 2.18.0\n",
      "Uninstalling tensorflow-2.18.0:\n",
      "  Successfully uninstalled tensorflow-2.18.0\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3544f852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (4.25.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (1.67.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (13.8.1)\n",
      "Requirement already satisfied: namex in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (0.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging->tensorflow) (3.1.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Using cached tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.3 MB)\n",
      "Installing collected packages: tensorflow\n",
      "Successfully installed tensorflow-2.18.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0569cc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.0+cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-31 19:55:08.555284: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1730404508.575561    7794 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1730404508.581708    7794 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-31 19:55:08.601705: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b85f21e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9022f44c",
   "metadata": {},
   "source": [
    "### Step 1: Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b062f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
      "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
      "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
      "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
      "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
      "\n",
      "                                                text subject  \\\n",
      "0  Donald Trump just couldn t wish all Americans ...    News   \n",
      "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
      "2  On Friday, it was revealed that former Milwauk...    News   \n",
      "3  On Christmas day, Donald Trump announced that ...    News   \n",
      "4  Pope Francis used his annual Christmas Day mes...    News   \n",
      "\n",
      "                date  \n",
      "0  December 31, 2017  \n",
      "1  December 31, 2017  \n",
      "2  December 30, 2017  \n",
      "3  December 29, 2017  \n",
      "4  December 25, 2017  \n",
      "                                               title  \\\n",
      "0  As U.S. budget fight looms, Republicans flip t...   \n",
      "1  U.S. military to accept transgender recruits o...   \n",
      "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
      "3  FBI Russia probe helped by Australian diplomat...   \n",
      "4  Trump wants Postal Service to charge 'much mor...   \n",
      "\n",
      "                                                text       subject  \\\n",
      "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
      "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
      "2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
      "3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
      "4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
      "\n",
      "                 date  \n",
      "0  December 31, 2017   \n",
      "1  December 29, 2017   \n",
      "2  December 31, 2017   \n",
      "3  December 30, 2017   \n",
      "4  December 29, 2017   \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "fake_df = pd.read_csv('fake_news_data/Fake.csv')\n",
    "real_df = pd.read_csv('fake_news_data/True.csv')\n",
    "\n",
    "# Display the first few rows of each DataFrame to confirm loading\n",
    "print(fake_df.head())\n",
    "print(real_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecad4af",
   "metadata": {},
   "source": [
    "### Step 2: Add a Label Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee1e2d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a label column\n",
    "fake_df['label'] = 0  # 0 for fake news\n",
    "real_df['label'] = 1   # 1 for real news"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd0d0cc",
   "metadata": {},
   "source": [
    "### Step 3: Combine the DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d530d6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
      "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
      "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
      "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
      "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
      "\n",
      "                                                text subject  \\\n",
      "0  Donald Trump just couldn t wish all Americans ...    News   \n",
      "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
      "2  On Friday, it was revealed that former Milwauk...    News   \n",
      "3  On Christmas day, Donald Trump announced that ...    News   \n",
      "4  Pope Francis used his annual Christmas Day mes...    News   \n",
      "\n",
      "                date  label  \n",
      "0  December 31, 2017      0  \n",
      "1  December 31, 2017      0  \n",
      "2  December 30, 2017      0  \n",
      "3  December 29, 2017      0  \n",
      "4  December 25, 2017      0  \n"
     ]
    }
   ],
   "source": [
    "# Combine the two DataFrames\n",
    "train_df = pd.concat([fake_df, real_df], ignore_index=True)\n",
    "\n",
    "# Display the first few rows of the combined DataFrame\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c1551a",
   "metadata": {},
   "source": [
    "### Step 4: Prepare Labels for Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "754cf920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the labels\n",
    "train_labels = train_df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c616e6",
   "metadata": {},
   "source": [
    "### Step 5: Optional - Split into Train/Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "369f76be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into training and testing sets (you can adjust the test_size as needed)\n",
    "train_df, test_df = train_test_split(train_df, test_size=0.2, random_state=42, stratify=train_df['label'])\n",
    "\n",
    "# Prepare labels for the test set\n",
    "test_labels = test_df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d37550",
   "metadata": {},
   "source": [
    "### Step 6: Preprocess the Data for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea95da0",
   "metadata": {},
   "source": [
    "#### Import the Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d6c1af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0c23a87743e40d4a6bb00a3797698a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12a6687728df4b6c8667019bb4ee5c82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "003a7e44e6574d34bb48545000093d9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5be94fb44284430974be43fdb8be1c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load pre-trained BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f472ef",
   "metadata": {},
   "source": [
    "#### Tokenize the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aba7bbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the training data\n",
    "train_encodings = tokenizer(list(train_df['text']), truncation=True, padding=True, max_length=512)\n",
    "\n",
    "# Tokenize the testing data\n",
    "test_encodings = tokenizer(list(test_df['text']), truncation=True, padding=True, max_length=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620d7f47",
   "metadata": {},
   "source": [
    "### Step 7: Prepare Data for the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c620b612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class NewsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbd5ceb",
   "metadata": {},
   "source": [
    "#### Create Dataset Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "910fcdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = NewsDataset(train_encodings, list(train_df['label']))\n",
    "test_dataset = NewsDataset(test_encodings, list(test_df['label']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc68074",
   "metadata": {},
   "source": [
    "### Step 8: Set Up the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bd33d6",
   "metadata": {},
   "source": [
    "#### Import and Load the Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b1820f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c31ae2d5d085434fa80b2e7faf0ed213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d567e9df",
   "metadata": {},
   "source": [
    "#### Set Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed6fe7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          \n",
    "    num_train_epochs=1.5, \n",
    "    save_total_limit=2,\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=16,  \n",
    "    per_device_eval_batch_size=16,   \n",
    "    warmup_steps=500,                \n",
    "    weight_decay=0.01,               \n",
    "    logging_dir='./logs',            \n",
    "    logging_steps=1000,\n",
    "    evaluation_strategy=\"no\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294bcc99",
   "metadata": {},
   "source": [
    "### Step 9: Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68d4f4c",
   "metadata": {},
   "source": [
    "#### Initialize the Trainer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fafeb3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,                         \n",
    "    args=training_args,                  \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=test_dataset             \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f041c047",
   "metadata": {},
   "source": [
    "#### Train the Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "910b1a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3368' max='3368' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3368/3368 7:10:49, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.003900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.001400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3368, training_loss=0.0011594385404201698, metrics={'train_runtime': 25867.4748, 'train_samples_per_second': 2.083, 'train_steps_per_second': 0.13, 'total_flos': 1.417800232912896e+16, 'train_loss': 0.0011594385404201698, 'epoch': 1.5002227171492204})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_checkpoint = \"./results/checkpoint-1500\"\n",
    "\n",
    "trainer.train(resume_from_checkpoint=last_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51140898",
   "metadata": {},
   "source": [
    "### Step 10: Evaluate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a24a863",
   "metadata": {},
   "source": [
    "#### Define Compute Metrics Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34b86256",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f064ccd",
   "metadata": {},
   "source": [
    "#### Evaluate the Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91ad35d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='562' max='562' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [562/562 38:52]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0002313898439751938, 'eval_runtime': 2336.4503, 'eval_samples_per_second': 3.843, 'eval_steps_per_second': 0.241, 'epoch': 1.5002227171492204}\n"
     ]
    }
   ],
   "source": [
    "results = trainer.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac27b965",
   "metadata": {},
   "source": [
    "### Save the Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6895478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./fake_news_model/tokenizer_config.json',\n",
       " './fake_news_model/special_tokens_map.json',\n",
       " './fake_news_model/vocab.txt',\n",
       " './fake_news_model/added_tokens.json')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### model.save_pretrained('./fake_news_model')\n",
    "tokenizer.save_pretrained('./fake_news_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8935fc",
   "metadata": {},
   "source": [
    "### Step 11: Test the Model with New Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e89ba00",
   "metadata": {},
   "source": [
    "#### Tokenize the New Text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a6bf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text = \"Enter a news article here to test\"\n",
    "inputs = tokenizer(new_text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b5e14b",
   "metadata": {},
   "source": [
    "#### Run the Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ec7fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(**inputs)\n",
    "logits = outputs.logits\n",
    "predicted_class = torch.argmax(logits, dim=1).item()\n",
    "print(\"Fake\" if predicted_class == 0 else \"Real\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5419600f",
   "metadata": {},
   "source": [
    "### Push to GitHub in SageMaker terminal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765a8cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "git init\n",
    "git add .\n",
    "git commit -m \"Add fake news detection model\"\n",
    "git remote add origin <your-repo-url>\n",
    "git push -u origin main"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
